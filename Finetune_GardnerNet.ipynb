{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from tqdm import trange, tqdm\n",
    "import os\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import timm\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "import copy\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(src_img_dir, all_img_names):\n",
    "    \n",
    "    tf_to_tensor = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "    #all_img_names = [f for f in os.listdir(src_img_dir) if os.path.isfile(os.path.join(src_img_dir, f))]\n",
    "    \n",
    "    #VAR[X] = E[X**2] - E[X]**2\n",
    "    channel_sum, channel_squared_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for idx in trange(len(all_img_names)):\n",
    "        #data = data.repeat(1, 3, 1, 1)\n",
    "        #data shape: batchSize, 1, H, W\n",
    "\n",
    "        cur_loaded_img = cv2.imdecode(np.fromfile(src_img_dir+all_img_names[idx], dtype= np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "        cur_pil_img = Image.fromarray(cur_loaded_img)\n",
    "        tensor_img = tf_to_tensor(cur_pil_img).unsqueeze(0)\n",
    "\n",
    "        channel_sum += torch.mean( tensor_img, dim=[0,2,3])\n",
    "        channel_squared_sum += torch.mean(tensor_img**2, dim=[0,2,3])\n",
    "        num_batches = num_batches + 1\n",
    "\n",
    "    mean = channel_sum / num_batches\n",
    "    std = (channel_squared_sum/num_batches - mean**2)**0.5\n",
    "\n",
    "    return mean.item(), std.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlastocystFocalDataset(Dataset):\n",
    "    def __init__(self, df_excel, src_img_dir, resize, dataset_mean, dataset_std, num_multifocus_imgs, is_train):\n",
    "      super(BlastocystFocalDataset, self).__init__()\n",
    "\n",
    "      self.df_excel = df_excel\n",
    "      self.resize = resize\n",
    "      self.MEAN = dataset_mean\n",
    "      self.STD  = dataset_std\n",
    "\n",
    "      self.is_train = is_train\n",
    "\n",
    "      self.list_of_img_list = []\n",
    "      self.expansion_labels_list = []\n",
    "      self.icm_labels_list = []\n",
    "      self.te_labels_list = []\n",
    "\n",
    "      focus_name_columns = self.df_excel.columns.to_list()[:num_multifocus_imgs]\n",
    "      label_columns = self.df_excel.columns.to_list()[num_multifocus_imgs:]\n",
    "      \n",
    "      min_expansion_label = self.df_excel[ label_columns[0] ].min()\n",
    "      min_icm_label = self.df_excel[ label_columns[1] ].min()\n",
    "      min_te_label = self.df_excel[ label_columns[2] ].min()\n",
    "      \n",
    "\n",
    "      for idx in trange( len(self.df_excel)  ):\n",
    "\n",
    "        cur_img_list = []\n",
    "        for focus_name in focus_name_columns:\n",
    "            \n",
    "            cur_img_name = df_excel.iloc[idx][focus_name]\n",
    "\n",
    "            cur_img_full_path = src_img_dir + cur_img_name\n",
    "            cur_loaded_img = cv2.imdecode(np.fromfile(cur_img_full_path, dtype= np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if self.resize != 500:\n",
    "                cur_loaded_img = cv2.resize( cur_loaded_img, (self.resize,self.resize), cv2.INTER_AREA  )\n",
    "\n",
    "            cur_img_list.append(cur_loaded_img)\n",
    "        self.list_of_img_list.append(cur_img_list)\n",
    "\n",
    "        cur_expansion_label  = int( self.df_excel.iloc[idx][ label_columns[0] ] - min_expansion_label   )\n",
    "        cur_icm_label = int( self.df_excel.iloc[idx][ label_columns[1] ] - min_icm_label  )     # 1(A), 2(B), 3(C)\n",
    "        cur_te_label  = int( self.df_excel.iloc[idx][ label_columns[2] ] - min_te_label   )    # 1(A), 2(B), 3(C)\n",
    "\n",
    "        self.expansion_labels_list.append(  cur_expansion_label    )\n",
    "        self.icm_labels_list.append( cur_icm_label   )\n",
    "        self.te_labels_list.append(  cur_te_label    )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.df_excel.index)\n",
    "\n",
    "\n",
    "    def denormalize(self, x_hat):\n",
    "\n",
    "        img_mean = self.MEAN\n",
    "        img_std = self.STD\n",
    "        x = x_hat * img_std + img_mean\n",
    "        return x\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # ds label\n",
    "        expansion_label_outcome_list = self.expansion_labels_list[idx]\n",
    "        expansion_label_outcome_array = np.array([expansion_label_outcome_list])\n",
    "        expansion_label_outcome_float_array = expansion_label_outcome_array.astype('float')\n",
    "        expansion_label_outcome_tensor = torch.from_numpy(expansion_label_outcome_float_array)\n",
    "        expansion_label_outcome_long_tensor = expansion_label_outcome_tensor.to(torch.long)\n",
    "        # icm label\n",
    "        icm_label_outcome_list = self.icm_labels_list[idx]\n",
    "        icm_label_outcome_array = np.array([icm_label_outcome_list])\n",
    "        icm_label_outcome_float_array = icm_label_outcome_array.astype('float')\n",
    "        icm_label_outcome_tensor = torch.from_numpy(icm_label_outcome_float_array)\n",
    "        icm_label_outcome_long_tensor = icm_label_outcome_tensor.to(torch.long)\n",
    "        # te label\n",
    "        te_label_outcome_list = self.te_labels_list[idx]\n",
    "        te_label_outcome_array = np.array([te_label_outcome_list])\n",
    "        te_label_outcome_float_array = te_label_outcome_array.astype('float')\n",
    "        te_label_outcome_tensor = torch.from_numpy(te_label_outcome_float_array)\n",
    "        te_label_outcome_long_tensor = te_label_outcome_tensor.to(torch.long)\n",
    "\n",
    "        rotation_degree = random.randrange(0, 350, 10)\n",
    "        brightness_factor = random.randrange(7, 13, 1); brightness_factor = brightness_factor / 10.0\n",
    "        tf_to_tensor = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "        opencv_img_list_raw = self.list_of_img_list[idx]\n",
    "        tensor_img_list = []\n",
    "\n",
    "        for img_idx in range( len(opencv_img_list_raw)  ):\n",
    "\n",
    "            cur_opencv_img = opencv_img_list_raw[img_idx]\n",
    "            cur_pil_img = Image.fromarray(cur_opencv_img)\n",
    "\n",
    "            if self.is_train:\n",
    "                # rotation\n",
    "                cur_pil_img = cur_pil_img.rotate(angle= rotation_degree, fillcolor= int(self.MEAN*255)) # rotate\n",
    "                # adjust brightness\n",
    "                enhancer = ImageEnhance.Brightness(cur_pil_img)\n",
    "                cur_pil_img = enhancer.enhance(brightness_factor)\n",
    "\n",
    "            tensor_img = tf_to_tensor(cur_pil_img)\n",
    "            tensor_img = (tensor_img - self.MEAN) / self.STD\n",
    "            tensor_img_list.append(tensor_img)\n",
    "\n",
    "        final_tensor_img = torch.cat( tensor_img_list, dim= 0  )\n",
    "\n",
    "        return final_tensor_img, expansion_label_outcome_long_tensor, icm_label_outcome_long_tensor, te_label_outcome_long_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GardnerNet(nn.Module):\n",
    "    def __init__(self, num_of_multifocus_images, num_expansion_classes):\n",
    "        super(GardnerNet, self).__init__()\n",
    "\n",
    "        self.model_ft = timm.create_model( 'resnet152', pretrained= False, in_chans= 1, num_classes= 2)\n",
    "        self.num_ftrs = self.model_ft.fc.in_features\n",
    "        self.model_ft.fc = nn.Identity()\n",
    "\n",
    "        self.number_of_multifocus_images = num_of_multifocus_images\n",
    "\n",
    "        self.ds_layer = nn.Linear(self.num_ftrs*num_of_multifocus_images, num_expansion_classes)   # expansion: 3, 4, 5, 6\n",
    "        self.icm_layer = nn.Linear(self.num_ftrs*num_of_multifocus_images, 3)  # (1)(A)(good), (2)(B)(fair), (3)(C)(poor)\n",
    "        self.te_layer = nn.Linear(self.num_ftrs*num_of_multifocus_images, 3)   # (1)(A)(good), (2)(B)(fair), (3)(C)(poor)\n",
    "\n",
    "        self.softmax_op = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x): # x.shape: batch, number_of_multifocus_images, height, width\n",
    "        features = []\n",
    "        for idx in range( x.shape[1] ):\n",
    "            features.append( self.model_ft( x[:,idx,:].unsqueeze(1)  )  )\n",
    "\n",
    "        concatenated_features = torch.cat( features, dim=1  )\n",
    "\n",
    "        expansion_out  = self.ds_layer(concatenated_features)\n",
    "        icm_out = self.icm_layer(concatenated_features)\n",
    "        te_out  = self.te_layer(concatenated_features)\n",
    "\n",
    "        return expansion_out, icm_out, te_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Val, Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( model, device, dataloader_source, criterion_ds, criterion_icm, criterion_te, optimizer):\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  len_dataloader   = len(dataloader_source)\n",
    "\n",
    "  with tqdm(total= len_dataloader) as pbar_batch:\n",
    "    for x, expansion_labels, icm_labels, te_labels in dataloader_source:\n",
    "        x = x.to(device)\n",
    "\n",
    "        expansion_labels = torch.squeeze(expansion_labels, 1)\n",
    "        expansion_labels = expansion_labels.to(device)\n",
    "\n",
    "        icm_labels = torch.squeeze(icm_labels, 1)\n",
    "        icm_labels = icm_labels.to(device)\n",
    "\n",
    "        te_labels = torch.squeeze(te_labels, 1)\n",
    "        te_labels = te_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        expansion_out, icm_out, te_out = model(x)\n",
    "\n",
    "        loss_ds =  criterion_ds(expansion_out,  expansion_labels)\n",
    "        loss_icm =  criterion_icm(icm_out,  icm_labels)\n",
    "        loss_te =  criterion_te(te_out,  te_labels)\n",
    "        loss = (loss_ds + loss_icm + loss_te) / 3.0\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar_batch.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_Curve(y_test, y_score):\n",
    "  fpr = dict()\n",
    "  tpr = dict()\n",
    "  n_classes = y_test.shape[1]\n",
    "\n",
    "  roc_auc = dict()\n",
    "  for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "  # Compute micro-average ROC curve and ROC area\n",
    "  fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "  # macro-average AUC\n",
    "  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "  # Then interpolate all ROC curves at this points\n",
    "  mean_tpr = np.zeros_like(all_fpr)\n",
    "  for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "  # Finally average it and compute AUC\n",
    "  mean_tpr /= n_classes\n",
    "  fpr[\"macro\"] = all_fpr\n",
    "  tpr[\"macro\"] = mean_tpr\n",
    "  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "  return roc_auc[\"macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_confusion_matrix(model, dataloaders, device, num_expansion_classes):\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  # expansion\n",
    "  expansion_running_corrects = 0\n",
    "  if 3 == num_expansion_classes:\n",
    "    expansion_confusion_matrix = np.zeros( (3, 3) ) # \n",
    "    expansion_look_up_table = [ [1,0,0], [0,1,0], [0,0,1] ]\n",
    "  elif 4 == num_expansion_classes:\n",
    "    expansion_confusion_matrix = np.zeros( (4, 4) ) # \n",
    "    expansion_look_up_table = [ [1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1] ]\n",
    "  expansion_truth = []; expansion_scores = []\n",
    "\n",
    "  # ICM\n",
    "  icm_running_corrects = 0\n",
    "  icm_confusion_matrix = np.zeros( (3, 3) )\n",
    "  icm_truth = []; icm_scores = []\n",
    "\n",
    "  # TE\n",
    "  te_running_corrects = 0\n",
    "  te_confusion_matrix = np.zeros( (3, 3) )\n",
    "  te_truth = []; te_scores = []\n",
    "\n",
    "  softmax_op = nn.Softmax(dim=1)\n",
    "\n",
    "  check_log = 0\n",
    "\n",
    "  tqdm_total = len(dataloaders)\n",
    "  with tqdm(total= tqdm_total) as bar:\n",
    "    with torch.no_grad():\n",
    "      for x, expansion_labels, icm_labels, te_labels in dataloaders:\n",
    "\n",
    "        x = x.to(device)\n",
    "\n",
    "        expansion_labels = torch.squeeze(expansion_labels, 1)\n",
    "        expansion_labels = expansion_labels.to(device)\n",
    "\n",
    "        icm_labels = torch.squeeze(icm_labels, 1)\n",
    "        icm_labels = icm_labels.to(device)\n",
    "\n",
    "        te_labels = torch.squeeze(te_labels, 1)\n",
    "        te_labels = te_labels.to(device)\n",
    "\n",
    "        expansion_out, icm_out, te_out = model(x)\n",
    "\n",
    "        # metric related to DS\n",
    "        _, expansion_preds = torch.max( expansion_out, 1)\n",
    "        expansion_running_corrects += torch.sum(expansion_preds == expansion_labels.data)\n",
    "        expansion_predict_numpy = expansion_preds.cpu().numpy()\n",
    "        rows = expansion_predict_numpy.shape[0]\n",
    "        for i in range(rows):\n",
    "          expansion_label_val = int(expansion_labels[i])\n",
    "          expansion_predict_val = int(expansion_predict_numpy[i])\n",
    "          expansion_confusion_matrix[expansion_label_val][expansion_predict_val] += 1\n",
    "        # save scores & labels\n",
    "        expansion_out = softmax_op( expansion_out  )\n",
    "        for bIdx in range(expansion_out.shape[0]):\n",
    "          expansion_truth.append( expansion_look_up_table[ expansion_labels[bIdx].data.cpu().numpy() ] ); expansion_scores.append(expansion_out[bIdx,:].data.cpu().numpy())\n",
    "\n",
    "        # metric related to ICM\n",
    "        _, icm_preds = torch.max( icm_out, 1)\n",
    "        icm_running_corrects += torch.sum( icm_preds == icm_labels.data)\n",
    "        icm_predict_numpy = icm_preds.cpu().numpy()\n",
    "        rows = icm_predict_numpy.shape[0]\n",
    "        for i in range(rows):\n",
    "          icm_label_val = int(icm_labels[i])\n",
    "          icm_predict_val = int(icm_predict_numpy[i])\n",
    "          icm_confusion_matrix[icm_label_val][icm_predict_val] += 1\n",
    "      #save scores & labels\n",
    "        icm_out = softmax_op( icm_out  )\n",
    "        for bIdx in range(icm_out.shape[0]):\n",
    "          icm_look_up_table = [ [1,0,0], [0,1,0], [0,0,1] ]\n",
    "          icm_truth.append( icm_look_up_table[ icm_labels[bIdx].data.cpu().numpy() ] ); icm_scores.append(icm_out[bIdx,:].data.cpu().numpy())\n",
    "\n",
    "        # metric related to TE\n",
    "        _, te_preds = torch.max( te_out, 1)\n",
    "        te_running_corrects += torch.sum( te_preds == te_labels.data)\n",
    "        te_predict_numpy = te_preds.cpu().numpy()\n",
    "        rows = te_predict_numpy.shape[0]\n",
    "        for i in range(rows):\n",
    "          te_label_val = int(te_labels[i])\n",
    "          te_predict_val = int(te_predict_numpy[i])\n",
    "          te_confusion_matrix[te_label_val][te_predict_val] += 1\n",
    "        # save scores & labels\n",
    "        te_out = softmax_op( te_out  )\n",
    "        for bIdx in range(te_out.shape[0]):\n",
    "          te_look_up_table = [ [1,0,0], [0,1,0], [0,0,1] ]\n",
    "          te_truth.append( te_look_up_table[ te_labels[bIdx].data.cpu().numpy() ] ); te_scores.append(te_out[bIdx,:].data.cpu().numpy())\n",
    "\n",
    "        bar.update(1)\n",
    "\n",
    "  expansion_acc = expansion_running_corrects.double() / len(dataloaders.dataset)\n",
    "  expansion_truth = numpy.array(expansion_truth); expansion_scores = numpy.array(expansion_scores)\n",
    "  expansion_auc = ROC_Curve( expansion_truth, expansion_scores  )\n",
    "\n",
    "  icm_acc = icm_running_corrects.double() / len(dataloaders.dataset)\n",
    "  icm_truth = numpy.array(icm_truth); icm_scores = numpy.array(icm_scores)\n",
    "  icm_auc = ROC_Curve( icm_truth, icm_scores  )\n",
    "\n",
    "  te_acc = te_running_corrects.double() / len(dataloaders.dataset)\n",
    "  te_truth = numpy.array(te_truth); te_scores = numpy.array(te_scores)\n",
    "  te_auc = ROC_Curve( te_truth, te_scores  )\n",
    "\n",
    "  return expansion_auc, expansion_acc, expansion_confusion_matrix, icm_auc, icm_acc, icm_confusion_matrix, te_auc, te_acc, te_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetClassBalancedWeights(df, column_name):\n",
    "  df_copy = copy.deepcopy(df)\n",
    "\n",
    "  min_val = df_copy[column_name].min()\n",
    "  df_copy[column_name] = (df_copy[column_name] - min_val)\n",
    "\n",
    "  keys = np.unique( df_copy[column_name] )\n",
    "  values = class_weight.compute_class_weight(class_weight='balanced', classes= keys, y= df_copy[column_name].values)\n",
    "  values = torch.from_numpy(values)\n",
    "  values = values.to(torch.float32)\n",
    "\n",
    "  return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(hyper_parameters, df_train, df_val, df_test, \n",
    "                   expansion_column_name, icm_column_name, te_column_name, \n",
    "                   device, num_expansion_classes, src_img_dir,\n",
    "                   dataset_mean, dataset_std, num_multifocus_imgs, \n",
    "                   pretrained_model, model_save_dir):\n",
    "\n",
    "  # weight\n",
    "  expansion_class_weight = GetClassBalancedWeights(df_train, expansion_column_name)\n",
    "  expansion_class_weight = expansion_class_weight.to(device)\n",
    "\n",
    "  icm_class_weight = GetClassBalancedWeights(df_train, icm_column_name)\n",
    "  icm_class_weight = icm_class_weight.to(device)\n",
    "\n",
    "  te_class_weight = GetClassBalancedWeights(df_train, te_column_name)\n",
    "  te_class_weight = te_class_weight.to(device)\n",
    "\n",
    "\n",
    "  # hyper-parameters\n",
    "  image_size = hyper_parameters['image_size']\n",
    "  cur_batch_size = hyper_parameters['batch_size']\n",
    "  learning_rate = hyper_parameters['lr']\n",
    "  weight_decay = hyper_parameters['weight_decay']\n",
    "\n",
    "  # dataset\n",
    "  db_train = BlastocystFocalDataset(df_train, src_img_dir, image_size, dataset_mean, dataset_std, num_multifocus_imgs, is_train= True)\n",
    "  db_val   = BlastocystFocalDataset(df_val, src_img_dir, image_size, dataset_mean, dataset_std, num_multifocus_imgs, is_train= False)\n",
    "  db_test  = BlastocystFocalDataset(df_test, src_img_dir, image_size, dataset_mean, dataset_std, num_multifocus_imgs, is_train= False)\n",
    "\n",
    "\n",
    "  criterion_ds = torch.nn.CrossEntropyLoss(weight= expansion_class_weight)\n",
    "  criterion_icm = torch.nn.CrossEntropyLoss(weight= icm_class_weight)\n",
    "  criterion_te = torch.nn.CrossEntropyLoss(weight= te_class_weight)\n",
    "\n",
    "  # untrained net\n",
    "  model = GardnerNet(num_multifocus_imgs, num_expansion_classes)\n",
    "\n",
    "  # use pretrained encoder\n",
    "  model.model_ft = copy.deepcopy(pretrained_model.model_ft)\n",
    "\n",
    "  # multiple gpus training: \n",
    "  model = torch.nn.DataParallel(model, device_ids=[0,1,2,3])\n",
    "  model.to(device)\n",
    "\n",
    "  # params to update\n",
    "  params_to_update = []\n",
    "  for param in model.parameters():\n",
    "      if param.requires_grad == True:\n",
    "          params_to_update.append(param)\n",
    "\n",
    "\n",
    "  optimizer = optim.AdamW(params_to_update, lr= learning_rate, weight_decay= weight_decay )\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(db_train, batch_size= cur_batch_size, shuffle= True, drop_last=True)\n",
    "  val_loader = torch.utils.data.DataLoader(db_val, batch_size= 32, shuffle= False)\n",
    "  test_loader = torch.utils.data.DataLoader(db_test, batch_size= 32, shuffle= False)\n",
    "\n",
    "\n",
    "  MAX_EPOCH = 300\n",
    "  max_auc = 0\n",
    "  decrease_count = 0\n",
    "\n",
    "  best_model = ''\n",
    "  PATIENCE_COUNT = 10\n",
    "\n",
    "\n",
    "  for idx in range(MAX_EPOCH):\n",
    "    train_model( model, device, train_loader, criterion_ds, criterion_icm, criterion_te, optimizer)\n",
    "    (expansion_val_auc, expansion_val_acc, expansion_val_conf, \n",
    "     icm_val_auc, icm_val_acc, icm_val_conf, \n",
    "     te_val_auc, te_val_acc, te_val_conf) = test_model_confusion_matrix( model, val_loader, device, num_expansion_classes)\n",
    "\n",
    "    val_auc  = (expansion_val_auc + icm_val_auc + te_val_auc) / 3.0\n",
    "    val_acc  = (expansion_val_acc + icm_val_acc + te_val_acc) / 3.0\n",
    "\n",
    "    print('\\nEpoch: {}, mean_val_auc: {}'.format(idx, val_auc))\n",
    "    print( 'expansion_val_auc: {}, expansion_val_acc: {}, expansion_val_conf: {}'.format(expansion_val_auc, expansion_val_acc, expansion_val_conf) )\n",
    "    print( 'icm_val_auc: {}, icm_val_acc: {}, icm_val_conf: {}'.format(icm_val_auc, icm_val_acc, icm_val_conf) )\n",
    "    print( 'te_val_auc: {}, te_val_acc: {}, te_val_conf: {}'.format(te_val_auc, te_val_acc, te_val_conf) )\n",
    "\n",
    "    status = ''\n",
    "    if val_auc > max_auc:\n",
    "      max_auc = val_auc\n",
    "      decrease_count = 0\n",
    "      best_model =   copy.deepcopy(model)\n",
    "      status = 'success'\n",
    "    else:\n",
    "      status = 'failed'\n",
    "      decrease_count += 1\n",
    "      if PATIENCE_COUNT == decrease_count:\n",
    "        break\n",
    "\n",
    "    print(status)\n",
    "\n",
    "\n",
    "\n",
    "  (expansion_test_auc, expansion_test_acc, expansion_test_conf, \n",
    "   icm_test_auc, icm_test_acc, icm_test_conf, \n",
    "   te_test_auc, te_test_acc, te_test_conf)  = test_model_confusion_matrix( best_model, test_loader, device, num_expansion_classes)\n",
    "\n",
    "  test_auc  = (expansion_test_auc + icm_test_auc + te_test_auc) / 3.0\n",
    "  print('\\nmean_test_auc: {}'.format(test_auc))\n",
    "  print( 'expansion_test_auc: {}, expansion_test_acc: {}, expansion_test_conf: {}'.format(expansion_test_auc, expansion_test_acc, expansion_test_conf) )\n",
    "  print( 'icm_test_auc: {}, icm_test_acc: {}, icm_test_conf: {}'.format(icm_test_auc, icm_test_acc, icm_test_conf) )\n",
    "  print( 'te_test_auc: {}, te_test_acc: {}, te_test_conf: {}'.format(te_test_auc, te_test_acc, te_test_conf) )\n",
    "\n",
    "  torch.save( best_model.module.state_dict(), model_save_dir + 'final_model.pt' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print( device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load excel\n",
    "df = pd.read_excel( './fine-tune-dataset/df_5_focus.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffle = df.sample(frac=1, random_state= 66).reset_index(drop=True)\n",
    "\n",
    "TRAIN_SIZE = int( len(df_shuffle) * 0.8 )\n",
    "VAL_SIZE   = int( len(df_shuffle) * 0.10 )\n",
    "\n",
    "df_train = df_shuffle.iloc[ : TRAIN_SIZE ]\n",
    "df_val  = df_shuffle.iloc[ TRAIN_SIZE : TRAIN_SIZE+VAL_SIZE ]\n",
    "df_test      = df_shuffle.iloc[ TRAIN_SIZE+VAL_SIZE : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, stdev of the training dataset\n",
    "\n",
    "# get dataset mean, std\n",
    "src_img_dir = './fine-tune-dataset/imgs/'\n",
    "\n",
    "num_multifocus_imgs = 5\n",
    "img_name_columns = df_train.columns.tolist()[:num_multifocus_imgs]\n",
    "all_img_names = df_train[img_name_columns].values.flatten().tolist()\n",
    "\n",
    "dataset_mean, dataset_std = get_mean_std( src_img_dir, all_img_names )\n",
    "\n",
    "print( 'dataset mean: {}, stdev: {}'.format(dataset_mean, dataset_std) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model\n",
    "\n",
    "pretrained_pt = torch.load( './GardnerNet_Pretrained_1.pt', map_location= device )\n",
    "\n",
    "pretrained_model = GardnerNet(num_of_multifocus_images= 2, num_expansion_classes= 4)\n",
    "\n",
    "pretrained_model.load_state_dict( pretrained_pt )\n",
    "\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters= {'batch_size': 9, \n",
    "             'lr': 4.73345487439063e-05, \n",
    "             'weight_decay': 0.507309243983485, \n",
    "             'image_size': 300 }\n",
    "\n",
    "\n",
    "expansion_column_name = 'DS'\n",
    "icm_column_name = 'ICM'\n",
    "te_column_name = 'TE'\n",
    "\n",
    "num_expansion_classes = 3\n",
    "src_img_dir = './fine-tune-dataset/imgs/'\n",
    "num_multifocus_imgs = 5\n",
    "model_save_dir = './fine-tune-dataset/'\n",
    "\n",
    "train_evaluate(hyper_parameters, df_train, df_val, df_test, \n",
    "                   expansion_column_name, icm_column_name, te_column_name, \n",
    "                   device, num_expansion_classes, src_img_dir,\n",
    "                   dataset_mean, dataset_std, num_multifocus_imgs, \n",
    "                   pretrained_model, model_save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
