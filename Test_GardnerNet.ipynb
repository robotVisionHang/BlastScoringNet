{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( torch.__version__ )\n",
    "print( torch.version.cuda )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print( device )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "class GardnerNet(nn.Module):\n",
    "    def __init__(self, number_of_multifocus_images):\n",
    "        super(GardnerNet, self).__init__()\n",
    "\n",
    "        self.model_ft = timm.create_model( 'resnet152', pretrained= False, in_chans= 1, num_classes= 2)\n",
    "        self.num_ftrs = self.model_ft.fc.in_features\n",
    "        self.model_ft.fc = nn.Identity()\n",
    "\n",
    "        self.number_of_multifocus_images = number_of_multifocus_images\n",
    "\n",
    "        self.ds_layer = nn.Linear(self.num_ftrs*number_of_multifocus_images, 4)   # 3, 4, 5, 6\n",
    "        self.icm_layer = nn.Linear(self.num_ftrs*number_of_multifocus_images, 3)  # (1)(A)(good), (2)(B)(fair), (3)(C)(poor)\n",
    "        self.te_layer = nn.Linear(self.num_ftrs*number_of_multifocus_images, 3)   # (1)(A)(good), (2)(B)(fair), (3)(C)(poor)\n",
    "\n",
    "        self.softmax_op = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x): # x.shape: batch, number_of_multifocus_images, height, width\n",
    "        features = []\n",
    "        for idx in range( x.shape[1] ):\n",
    "            features.append( self.model_ft( x[:,idx,:].unsqueeze(1)  )  )\n",
    "\n",
    "        concatenated_features = torch.cat( features, dim=1  )\n",
    "\n",
    "        ds_out  = self.ds_layer(concatenated_features)\n",
    "        icm_out = self.icm_layer(concatenated_features)\n",
    "        te_out  = self.te_layer(concatenated_features)\n",
    "\n",
    "        return ds_out, icm_out, te_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path = './GardnerNet_Pretrained_1.pt'\n",
    "saved_model = torch.load( model_path, map_location= device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_multifocus_images = 2\n",
    "model = GardnerNet(number_of_multifocus_images)\n",
    "\n",
    "model.load_state_dict( saved_model )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process blastocyst images to get expansion degree grade (3-6), ICM score, and TE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(src_img_dir, src_img_name_list):\n",
    "    IMG_MEAN = 0.4800113\n",
    "    IMG_STD  = 0.073582366\n",
    "    IMG_SIZE = 300\n",
    "\n",
    "    tf_to_tensor = transforms.Compose([\n",
    "                transforms.Resize( (IMG_SIZE, IMG_SIZE) ),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "    \n",
    "    tensor_img_list = []\n",
    "    for idx in range( len(src_img_name_list) ):\n",
    "        cur_img = cv2.imdecode( np.fromfile( src_img_dir + src_img_name_list[idx], dtype=np.uint8), cv2.IMREAD_GRAYSCALE  )\n",
    "        pil_img = Image.fromarray(cur_img)\n",
    "        tensor_img = tf_to_tensor(pil_img)\n",
    "        tensor_img = (tensor_img - IMG_MEAN) / IMG_STD\n",
    "        tensor_img = torch.unsqueeze(tensor_img, 0)\n",
    "\n",
    "        tensor_img_list.append(tensor_img)\n",
    "\n",
    "    final_tensor_img = torch.cat( tensor_img_list, dim= 1 )\n",
    "\n",
    "    return final_tensor_img\n",
    "\n",
    "\n",
    "def Postprocess(ds_out, icm_out, te_out):\n",
    "    softmax_op = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    ds_prob  = softmax_op(ds_out)\n",
    "    icm_prob = softmax_op(icm_out)\n",
    "    te_prob  = softmax_op(te_out)\n",
    "\n",
    "    if ds_prob.is_cuda:\n",
    "        ds_prob_numpy_list  =  ds_prob.detach().cpu().numpy().tolist()\n",
    "        icm_prob_numpy_list =  icm_prob.detach().cpu().numpy().tolist()\n",
    "        te_prob_numpy_list  =  te_prob.detach().cpu().numpy().tolist()\n",
    "    else:\n",
    "        ds_prob_numpy_list = ds_prob.detach().numpy().tolist()\n",
    "        icm_prob_numpy_list = icm_prob.detach().numpy().tolist()\n",
    "        te_prob_numpy_list = te_prob.detach().numpy().tolist()\n",
    "\n",
    "    expnasion_degree_grade = np.argmax(ds_prob_numpy_list[0]) + 3\n",
    "    icm_score = 4 - ( 1.0 * icm_prob_numpy_list[0][0] + 2.0 * icm_prob_numpy_list[0][1] + 3.0 * icm_prob_numpy_list[0][2] )\n",
    "    te_score  = 4 - ( 1.0 * te_prob_numpy_list[0][0]  + 2.0 * te_prob_numpy_list[0][1]  + 3.0 * te_prob_numpy_list[0][2] )\n",
    "\n",
    "    return expnasion_degree_grade, icm_score, te_score, icm_prob_numpy_list, te_prob_numpy_list\n",
    "\n",
    "\n",
    "def Process( src_img_dir, src_img_full_names, model, print_icm_result, print_te_result):\n",
    "    for idx in range( len(src_img_full_names) ):\n",
    "        cur_img_names = src_img_full_names[idx]\n",
    "        final_tensor_img = Preprocess( src_img_dir, cur_img_names )\n",
    "        final_tensor_img = final_tensor_img.to(device)\n",
    "\n",
    "        # inference\n",
    "        ds_out, icm_out, te_out = model( final_tensor_img )\n",
    "\n",
    "        expnasion_degree_grade, icm_score, te_score, icm_prob_numpy_list, te_prob_numpy_list = Postprocess( ds_out, icm_out, te_out )\n",
    "\n",
    "        print('Sample {}'.format(idx+1))\n",
    "        print( '\\texpnasion_degree_grade: {}'.format(expnasion_degree_grade) )\n",
    "        if print_icm_result:\n",
    "            print( '\\ticm_score: {}, icm_prob: {}'.format(icm_score, icm_prob_numpy_list) )\n",
    "        if print_te_result:\n",
    "            print( '\\tte_score: {},  te_prob: {}'.format(te_score, te_prob_numpy_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dir and img_names\n",
    "\n",
    "fig_1_img_dir = './figure-1-imgs/'\n",
    "fig_1_img_names = [ ['fig1_focus1.jpg', 'fig1_focus2.jpg'] ]\n",
    "\n",
    "fig_3_img_dir = './figure-3-imgs/'\n",
    "fig_3_img_names = [[ 'fig3_sample1_focus1.jpg', 'fig3_sample1_focus2.jpg'], \n",
    "              ['fig3_sample2_focus1.jpg', 'fig3_sample2_focus2.jpg'],\n",
    "              ['fig3_sample3_focus1.jpg', 'fig3_sample3_focus2.jpg'],\n",
    "              ['fig3_sample4_focus1.jpg', 'fig3_sample4_focus2.jpg'],\n",
    "              ['fig3_sample5_focus1.jpg', 'fig3_sample5_focus2.jpg']\n",
    "            ]\n",
    "\n",
    "\n",
    "fig_4_img_dir = './figure-4-imgs/'\n",
    "fig_4_img_names = [ ['fig4_sample1_focus1.jpg', 'fig4_sample1_focus2.jpg'], \n",
    "              ['fig4_sample2_focus1.jpg', 'fig4_sample2_focus2.jpg'],\n",
    "              ['fig4_sample3_focus1.jpg', 'fig4_sample3_focus2.jpg'],\n",
    "              ['fig4_sample4_focus1.jpg', 'fig4_sample4_focus2.jpg'],\n",
    "              ['fig4_sample5_focus1.jpg', 'fig4_sample5_focus2.jpg']\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process\n",
    "\n",
    "print( '***Figure 1' )\n",
    "Process( fig_1_img_dir, fig_1_img_names, model, print_icm_result= True, print_te_result= True )\n",
    "\n",
    "\n",
    "print( '\\n***Figure 3' )\n",
    "Process( fig_3_img_dir, fig_3_img_names, model, print_icm_result= True, print_te_result= False  )\n",
    "\n",
    "\n",
    "print( '\\n***Figure 4' )\n",
    "Process( fig_4_img_dir, fig_4_img_names, model, print_icm_result= False, print_te_result= True )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
